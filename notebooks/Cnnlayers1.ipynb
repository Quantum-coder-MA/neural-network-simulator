{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b22c079-a400-4387-9061-7259f05f13b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 23:39:52.116459: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-18 23:39:52.760358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-18 23:39:55.030788: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02c4baf-cee2-40fb-8225-26b9288a8341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5275c8-f564-4239-a23e-a3b9fe2933c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected and configured: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Place this at the very top of your script, right after imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. Check if a GPU is detected\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 2. Configure memory growth (better than a fixed fraction)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # 3. Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"GPUs detected and configured: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Falling back to CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4585821-f303-43f4-81d6-8792c8bc5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected and configured: /physical_device:GPU:0\n",
      "1-conv-64-nodes-0-dense-1766097619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nigga/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1766097620.091780     452 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 23:40:23.682439: I external/local_xla/xla/service/service.cc:163] XLA service 0x721030008940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-18 23:40:23.682523: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-12-18 23:40:23.713961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-18 23:40:23.868328: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 17/479\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4519 - loss: 1.0835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766097625.301232     536 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6734 - loss: 0.6105 - val_accuracy: 0.6374 - val_loss: 0.6551\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7614 - loss: 0.4996 - val_accuracy: 0.7627 - val_loss: 0.4952\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8065 - loss: 0.4360 - val_accuracy: 0.7711 - val_loss: 0.4823\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8277 - loss: 0.3898 - val_accuracy: 0.7787 - val_loss: 0.4826\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8532 - loss: 0.3498 - val_accuracy: 0.7770 - val_loss: 0.4816\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8677 - loss: 0.3160 - val_accuracy: 0.7788 - val_loss: 0.5050\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8863 - loss: 0.2829 - val_accuracy: 0.7747 - val_loss: 0.5084\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9002 - loss: 0.2608 - val_accuracy: 0.7718 - val_loss: 0.5317\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.2298 - val_accuracy: 0.7741 - val_loss: 0.5521\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9281 - loss: 0.2036 - val_accuracy: 0.7650 - val_loss: 0.5795\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9379 - loss: 0.1843 - val_accuracy: 0.7683 - val_loss: 0.5873\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9494 - loss: 0.1593 - val_accuracy: 0.7692 - val_loss: 0.5960\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9553 - loss: 0.1448 - val_accuracy: 0.7627 - val_loss: 0.6418\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9686 - loss: 0.1214 - val_accuracy: 0.7602 - val_loss: 0.6690\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1138 - val_accuracy: 0.7660 - val_loss: 0.6651\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.1000 - val_accuracy: 0.7641 - val_loss: 0.7075\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.0842 - val_accuracy: 0.7644 - val_loss: 0.7208\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.0715 - val_accuracy: 0.7604 - val_loss: 0.8012\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0622 - val_accuracy: 0.7627 - val_loss: 0.7726\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0538 - val_accuracy: 0.7596 - val_loss: 0.8083\n",
      "2-conv-64-nodes-0-dense-1766097707\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.6915 - loss: 0.5831 - val_accuracy: 0.7287 - val_loss: 0.5452\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7710 - loss: 0.4915 - val_accuracy: 0.7948 - val_loss: 0.4695\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7956 - loss: 0.4427 - val_accuracy: 0.7947 - val_loss: 0.4496\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8151 - loss: 0.4148 - val_accuracy: 0.8012 - val_loss: 0.4363\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8322 - loss: 0.3830 - val_accuracy: 0.8183 - val_loss: 0.4084\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8504 - loss: 0.3532 - val_accuracy: 0.7994 - val_loss: 0.4395\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8561 - loss: 0.3309 - val_accuracy: 0.8116 - val_loss: 0.4350\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8693 - loss: 0.3064 - val_accuracy: 0.8110 - val_loss: 0.4272\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8834 - loss: 0.2810 - val_accuracy: 0.8157 - val_loss: 0.4333\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8940 - loss: 0.2556 - val_accuracy: 0.8223 - val_loss: 0.4257\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9029 - loss: 0.2384 - val_accuracy: 0.8249 - val_loss: 0.4428\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9153 - loss: 0.2097 - val_accuracy: 0.8115 - val_loss: 0.4757\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9226 - loss: 0.1940 - val_accuracy: 0.7907 - val_loss: 0.5672\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9340 - loss: 0.1744 - val_accuracy: 0.8023 - val_loss: 0.5023\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9415 - loss: 0.1550 - val_accuracy: 0.8136 - val_loss: 0.5343\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9496 - loss: 0.1350 - val_accuracy: 0.8169 - val_loss: 0.5320\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9558 - loss: 0.1213 - val_accuracy: 0.8008 - val_loss: 0.5935\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9645 - loss: 0.1046 - val_accuracy: 0.8113 - val_loss: 0.5862\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9682 - loss: 0.0928 - val_accuracy: 0.8083 - val_loss: 0.6208\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9730 - loss: 0.0812 - val_accuracy: 0.8121 - val_loss: 0.6656\n",
      "3-conv-64-nodes-0-dense-1766097824\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6801 - loss: 0.6016 - val_accuracy: 0.7141 - val_loss: 0.5726\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7648 - loss: 0.4959 - val_accuracy: 0.7711 - val_loss: 0.4859\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.4355 - val_accuracy: 0.7977 - val_loss: 0.4289\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8200 - loss: 0.4006 - val_accuracy: 0.8043 - val_loss: 0.4288\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8353 - loss: 0.3688 - val_accuracy: 0.8163 - val_loss: 0.3982\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8575 - loss: 0.3343 - val_accuracy: 0.8314 - val_loss: 0.3808\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8713 - loss: 0.3085 - val_accuracy: 0.8331 - val_loss: 0.3939\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8829 - loss: 0.2781 - val_accuracy: 0.8534 - val_loss: 0.3358\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8951 - loss: 0.2531 - val_accuracy: 0.8532 - val_loss: 0.3370\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9059 - loss: 0.2299 - val_accuracy: 0.8595 - val_loss: 0.3348\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9176 - loss: 0.2029 - val_accuracy: 0.8554 - val_loss: 0.3428\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.1795 - val_accuracy: 0.8619 - val_loss: 0.3403\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9394 - loss: 0.1543 - val_accuracy: 0.8470 - val_loss: 0.3728\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9445 - loss: 0.1408 - val_accuracy: 0.8409 - val_loss: 0.4010\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9561 - loss: 0.1154 - val_accuracy: 0.8477 - val_loss: 0.4310\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9630 - loss: 0.1014 - val_accuracy: 0.8465 - val_loss: 0.4477\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9697 - loss: 0.0802 - val_accuracy: 0.8500 - val_loss: 0.4528\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9754 - loss: 0.0670 - val_accuracy: 0.8615 - val_loss: 0.4526\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9788 - loss: 0.0613 - val_accuracy: 0.8528 - val_loss: 0.5071\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9819 - loss: 0.0524 - val_accuracy: 0.8561 - val_loss: 0.5357\n",
      "1-conv-128-nodes-0-dense-1766097944\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6945 - loss: 0.5848 - val_accuracy: 0.7465 - val_loss: 0.5162\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7786 - loss: 0.4778 - val_accuracy: 0.7683 - val_loss: 0.5030\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8149 - loss: 0.4117 - val_accuracy: 0.7392 - val_loss: 0.5372\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.8455 - loss: 0.3626 - val_accuracy: 0.7676 - val_loss: 0.5127\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8677 - loss: 0.3157 - val_accuracy: 0.7590 - val_loss: 0.5464\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8847 - loss: 0.2834 - val_accuracy: 0.7734 - val_loss: 0.5367\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9105 - loss: 0.2369 - val_accuracy: 0.7493 - val_loss: 0.5958\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9257 - loss: 0.2073 - val_accuracy: 0.7740 - val_loss: 0.5733\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.1756 - val_accuracy: 0.7683 - val_loss: 0.6083\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1431 - val_accuracy: 0.7711 - val_loss: 0.6301\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9645 - loss: 0.1230 - val_accuracy: 0.7520 - val_loss: 0.7259\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.1021 - val_accuracy: 0.7676 - val_loss: 0.6838\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9825 - loss: 0.0829 - val_accuracy: 0.7526 - val_loss: 0.8119\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0686 - val_accuracy: 0.7667 - val_loss: 0.7555\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9923 - loss: 0.0540 - val_accuracy: 0.7685 - val_loss: 0.8156\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9956 - loss: 0.0426 - val_accuracy: 0.7639 - val_loss: 0.8373\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9954 - loss: 0.0379 - val_accuracy: 0.7644 - val_loss: 0.8783\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0274 - val_accuracy: 0.7654 - val_loss: 0.9340\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0316 - val_accuracy: 0.7459 - val_loss: 1.0684\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0213 - val_accuracy: 0.7650 - val_loss: 0.9964\n",
      "2-conv-128-nodes-0-dense-1766098064\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.6737 - loss: 0.6062 - val_accuracy: 0.7260 - val_loss: 0.5570\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7428 - loss: 0.5276 - val_accuracy: 0.7692 - val_loss: 0.4917\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7747 - loss: 0.4767 - val_accuracy: 0.7822 - val_loss: 0.4743\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7991 - loss: 0.4386 - val_accuracy: 0.7971 - val_loss: 0.4490\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8139 - loss: 0.4126 - val_accuracy: 0.8063 - val_loss: 0.4244\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.8311 - loss: 0.3804 - val_accuracy: 0.8116 - val_loss: 0.4147\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8464 - loss: 0.3525 - val_accuracy: 0.7952 - val_loss: 0.4434\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8590 - loss: 0.3301 - val_accuracy: 0.8148 - val_loss: 0.4169\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8726 - loss: 0.3019 - val_accuracy: 0.8192 - val_loss: 0.4228\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8865 - loss: 0.2760 - val_accuracy: 0.8127 - val_loss: 0.4326\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8959 - loss: 0.2531 - val_accuracy: 0.8145 - val_loss: 0.4461\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.9051 - loss: 0.2321 - val_accuracy: 0.7930 - val_loss: 0.5145\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9176 - loss: 0.2080 - val_accuracy: 0.8208 - val_loss: 0.4760\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9246 - loss: 0.1896 - val_accuracy: 0.8041 - val_loss: 0.5010\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9372 - loss: 0.1678 - val_accuracy: 0.8115 - val_loss: 0.5172\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9431 - loss: 0.1517 - val_accuracy: 0.8070 - val_loss: 0.5437\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9481 - loss: 0.1376 - val_accuracy: 0.8057 - val_loss: 0.6060\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9594 - loss: 0.1151 - val_accuracy: 0.8072 - val_loss: 0.5937\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9681 - loss: 0.0976 - val_accuracy: 0.7973 - val_loss: 0.6991\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9690 - loss: 0.0907 - val_accuracy: 0.8069 - val_loss: 0.6772\n",
      "3-conv-128-nodes-0-dense-1766098241\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.6719 - loss: 0.6112 - val_accuracy: 0.7144 - val_loss: 0.5614\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.7592 - loss: 0.5014 - val_accuracy: 0.7552 - val_loss: 0.4957\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8018 - loss: 0.4368 - val_accuracy: 0.8183 - val_loss: 0.4136\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8330 - loss: 0.3806 - val_accuracy: 0.8397 - val_loss: 0.3638\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8528 - loss: 0.3435 - val_accuracy: 0.8302 - val_loss: 0.3811\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8742 - loss: 0.2971 - val_accuracy: 0.8500 - val_loss: 0.3438\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8934 - loss: 0.2601 - val_accuracy: 0.8526 - val_loss: 0.3405\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9028 - loss: 0.2309 - val_accuracy: 0.8604 - val_loss: 0.3313\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9249 - loss: 0.1937 - val_accuracy: 0.8625 - val_loss: 0.3458\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9345 - loss: 0.1654 - val_accuracy: 0.8567 - val_loss: 0.3683\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9470 - loss: 0.1344 - val_accuracy: 0.8642 - val_loss: 0.3635\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9609 - loss: 0.1055 - val_accuracy: 0.8586 - val_loss: 0.4055\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9682 - loss: 0.0873 - val_accuracy: 0.8703 - val_loss: 0.4199\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9768 - loss: 0.0653 - val_accuracy: 0.8502 - val_loss: 0.5274\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 0.0525 - val_accuracy: 0.8576 - val_loss: 0.5039\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.0479 - val_accuracy: 0.8579 - val_loss: 0.5269\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9881 - loss: 0.0365 - val_accuracy: 0.8647 - val_loss: 0.5797\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9905 - loss: 0.0322 - val_accuracy: 0.8561 - val_loss: 0.5406\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.8470 - val_loss: 0.6984\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9959 - loss: 0.0171 - val_accuracy: 0.8654 - val_loss: 0.6836\n",
      "1-conv-256-nodes-0-dense-1766098425\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6638 - loss: 0.6296 - val_accuracy: 0.6914 - val_loss: 0.5745\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7664 - loss: 0.4987 - val_accuracy: 0.7612 - val_loss: 0.5084\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8094 - loss: 0.4264 - val_accuracy: 0.7528 - val_loss: 0.5168\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8384 - loss: 0.3700 - val_accuracy: 0.7644 - val_loss: 0.5109\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8673 - loss: 0.3140 - val_accuracy: 0.7714 - val_loss: 0.5176\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9010 - loss: 0.2586 - val_accuracy: 0.7584 - val_loss: 0.5802\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9224 - loss: 0.2148 - val_accuracy: 0.7577 - val_loss: 0.6242\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9362 - loss: 0.1778 - val_accuracy: 0.7686 - val_loss: 0.5900\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9555 - loss: 0.1416 - val_accuracy: 0.7615 - val_loss: 0.6440\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9682 - loss: 0.1118 - val_accuracy: 0.7670 - val_loss: 0.7067\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9799 - loss: 0.0857 - val_accuracy: 0.7540 - val_loss: 0.8041\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9869 - loss: 0.0650 - val_accuracy: 0.7500 - val_loss: 0.8413\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9895 - loss: 0.0566 - val_accuracy: 0.7532 - val_loss: 0.8843\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9952 - loss: 0.0404 - val_accuracy: 0.7703 - val_loss: 0.8658\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9971 - loss: 0.0315 - val_accuracy: 0.7660 - val_loss: 0.8853\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9976 - loss: 0.0263 - val_accuracy: 0.7567 - val_loss: 0.9731\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9989 - loss: 0.0203 - val_accuracy: 0.7654 - val_loss: 1.0285\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0193 - val_accuracy: 0.7639 - val_loss: 1.0524\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0183 - val_accuracy: 0.7604 - val_loss: 1.0909\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0129 - val_accuracy: 0.7633 - val_loss: 1.1201\n",
      "2-conv-256-nodes-0-dense-1766098613\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 23:56:55.580845: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 43ms/step - accuracy: 0.6711 - loss: 0.6092 - val_accuracy: 0.7554 - val_loss: 0.5214\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.7560 - loss: 0.5107 - val_accuracy: 0.7743 - val_loss: 0.4810\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.7951 - loss: 0.4528 - val_accuracy: 0.7612 - val_loss: 0.4900\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8096 - loss: 0.4235 - val_accuracy: 0.8025 - val_loss: 0.4354\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8339 - loss: 0.3808 - val_accuracy: 0.8182 - val_loss: 0.4162\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8468 - loss: 0.3532 - val_accuracy: 0.8128 - val_loss: 0.4157\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8622 - loss: 0.3209 - val_accuracy: 0.8040 - val_loss: 0.4332\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.8776 - loss: 0.2963 - val_accuracy: 0.8255 - val_loss: 0.4131\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.8876 - loss: 0.2670 - val_accuracy: 0.8214 - val_loss: 0.4209\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.8985 - loss: 0.2421 - val_accuracy: 0.8084 - val_loss: 0.4399\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9113 - loss: 0.2147 - val_accuracy: 0.8118 - val_loss: 0.4639\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.9230 - loss: 0.1903 - val_accuracy: 0.8113 - val_loss: 0.5034\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9350 - loss: 0.1632 - val_accuracy: 0.8019 - val_loss: 0.5954\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9451 - loss: 0.1451 - val_accuracy: 0.8104 - val_loss: 0.5287\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.9542 - loss: 0.1234 - val_accuracy: 0.8072 - val_loss: 0.6111\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9604 - loss: 0.1078 - val_accuracy: 0.8102 - val_loss: 0.5932\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9666 - loss: 0.0921 - val_accuracy: 0.8095 - val_loss: 0.6794\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.9739 - loss: 0.0783 - val_accuracy: 0.8023 - val_loss: 0.7087\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9783 - loss: 0.0653 - val_accuracy: 0.8093 - val_loss: 0.7449\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - accuracy: 0.9835 - loss: 0.0564 - val_accuracy: 0.8099 - val_loss: 0.7614\n",
      "3-conv-256-nodes-0-dense-1766098977\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 43ms/step - accuracy: 0.6649 - loss: 0.6190 - val_accuracy: 0.7147 - val_loss: 0.5586\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.7404 - loss: 0.5330 - val_accuracy: 0.7645 - val_loss: 0.4852\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.7794 - loss: 0.4689 - val_accuracy: 0.7958 - val_loss: 0.4387\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.8124 - loss: 0.4172 - val_accuracy: 0.8063 - val_loss: 0.4257\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.8339 - loss: 0.3691 - val_accuracy: 0.8360 - val_loss: 0.3645\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.8629 - loss: 0.3139 - val_accuracy: 0.8430 - val_loss: 0.3708\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8842 - loss: 0.2751 - val_accuracy: 0.8541 - val_loss: 0.3348\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9063 - loss: 0.2291 - val_accuracy: 0.8435 - val_loss: 0.3682\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9240 - loss: 0.1881 - val_accuracy: 0.8592 - val_loss: 0.3521\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9419 - loss: 0.1482 - val_accuracy: 0.8514 - val_loss: 0.3898\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9576 - loss: 0.1105 - val_accuracy: 0.8317 - val_loss: 0.5168\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9699 - loss: 0.0808 - val_accuracy: 0.8547 - val_loss: 0.4644\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.9764 - loss: 0.0647 - val_accuracy: 0.8567 - val_loss: 0.5329\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9849 - loss: 0.0470 - val_accuracy: 0.8665 - val_loss: 0.4790\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9881 - loss: 0.0387 - val_accuracy: 0.8526 - val_loss: 0.5571\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9867 - loss: 0.0358 - val_accuracy: 0.8438 - val_loss: 0.6615\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.9877 - loss: 0.0359 - val_accuracy: 0.8570 - val_loss: 0.5962\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9927 - loss: 0.0225 - val_accuracy: 0.8613 - val_loss: 0.6287\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9878 - loss: 0.0369 - val_accuracy: 0.8319 - val_loss: 0.7347\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.8596 - val_loss: 0.6746\n",
      "1-conv-64-nodes-1-dense-1766099381\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:09:43.977843: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-19 00:09:45.030210: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_453', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m471/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5528 - loss: 0.7467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:09:49.571258: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_184', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5864 - loss: 0.6889 - val_accuracy: 0.6731 - val_loss: 0.6383\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7052 - loss: 0.5822 - val_accuracy: 0.7296 - val_loss: 0.5515\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.4899 - val_accuracy: 0.7683 - val_loss: 0.4916\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.4166 - val_accuracy: 0.7692 - val_loss: 0.4976\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.3587 - val_accuracy: 0.7743 - val_loss: 0.4907\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8749 - loss: 0.2988 - val_accuracy: 0.7749 - val_loss: 0.5283\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.2392 - val_accuracy: 0.7726 - val_loss: 0.5567\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9289 - loss: 0.1910 - val_accuracy: 0.7633 - val_loss: 0.6170\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9500 - loss: 0.1444 - val_accuracy: 0.7706 - val_loss: 0.6703\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.1045 - val_accuracy: 0.7638 - val_loss: 0.7288\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9773 - loss: 0.0788 - val_accuracy: 0.7659 - val_loss: 0.7705\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.0537 - val_accuracy: 0.7750 - val_loss: 0.8920\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0376 - val_accuracy: 0.7531 - val_loss: 1.1797\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.0291 - val_accuracy: 0.7738 - val_loss: 1.0269\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0210 - val_accuracy: 0.7622 - val_loss: 1.0554\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0169 - val_accuracy: 0.7487 - val_loss: 1.3740\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9930 - loss: 0.0246 - val_accuracy: 0.7510 - val_loss: 1.4657\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0206 - val_accuracy: 0.7624 - val_loss: 1.2996\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0090 - val_accuracy: 0.7612 - val_loss: 1.4519\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9999 - loss: 0.0046 - val_accuracy: 0.7651 - val_loss: 1.4541\n",
      "2-conv-64-nodes-1-dense-1766099473\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:11:16.392892: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-19 00:11:17.564180: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_574', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7015 - loss: 0.5744 - val_accuracy: 0.7671 - val_loss: 0.4919\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7838 - loss: 0.4646 - val_accuracy: 0.7997 - val_loss: 0.4457\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8155 - loss: 0.4089 - val_accuracy: 0.7987 - val_loss: 0.4364\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8345 - loss: 0.3693 - val_accuracy: 0.8185 - val_loss: 0.4146\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8530 - loss: 0.3345 - val_accuracy: 0.7927 - val_loss: 0.4889\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8808 - loss: 0.2806 - val_accuracy: 0.8032 - val_loss: 0.4999\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8967 - loss: 0.2461 - val_accuracy: 0.8101 - val_loss: 0.4674\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9244 - loss: 0.1917 - val_accuracy: 0.8092 - val_loss: 0.5503\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9459 - loss: 0.1391 - val_accuracy: 0.8101 - val_loss: 0.5559\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9653 - loss: 0.0965 - val_accuracy: 0.8109 - val_loss: 0.6327\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.0706 - val_accuracy: 0.7991 - val_loss: 0.6915\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.0466 - val_accuracy: 0.8043 - val_loss: 0.8529\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0320 - val_accuracy: 0.7948 - val_loss: 0.9398\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9907 - loss: 0.0325 - val_accuracy: 0.7944 - val_loss: 1.0027\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.7984 - val_loss: 1.0308\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9902 - loss: 0.0306 - val_accuracy: 0.7982 - val_loss: 0.9992\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.0256 - val_accuracy: 0.8070 - val_loss: 1.0454\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.0159 - val_accuracy: 0.8049 - val_loss: 1.2035\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9937 - loss: 0.0200 - val_accuracy: 0.8034 - val_loss: 1.2107\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.0171 - val_accuracy: 0.7938 - val_loss: 1.2821\n",
      "3-conv-64-nodes-1-dense-1766099600\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:13:23.297768: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-19 00:13:24.510344: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_695', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.6688 - loss: 0.6089 - val_accuracy: 0.7368 - val_loss: 0.5353\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7723 - loss: 0.4791 - val_accuracy: 0.8016 - val_loss: 0.4388\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8077 - loss: 0.4208 - val_accuracy: 0.8012 - val_loss: 0.4522\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8270 - loss: 0.3876 - val_accuracy: 0.8276 - val_loss: 0.3873\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8540 - loss: 0.3377 - val_accuracy: 0.8296 - val_loss: 0.3825\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8710 - loss: 0.3032 - val_accuracy: 0.8497 - val_loss: 0.3458\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8835 - loss: 0.2760 - val_accuracy: 0.8448 - val_loss: 0.3516\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9029 - loss: 0.2368 - val_accuracy: 0.8424 - val_loss: 0.3933\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 0.2052 - val_accuracy: 0.8358 - val_loss: 0.4161\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9314 - loss: 0.1691 - val_accuracy: 0.8534 - val_loss: 0.4001\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.1402 - val_accuracy: 0.8317 - val_loss: 0.4960\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9536 - loss: 0.1205 - val_accuracy: 0.8485 - val_loss: 0.4487\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9654 - loss: 0.0930 - val_accuracy: 0.8413 - val_loss: 0.5206\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9749 - loss: 0.0668 - val_accuracy: 0.8366 - val_loss: 0.5790\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9811 - loss: 0.0545 - val_accuracy: 0.8374 - val_loss: 0.5770\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0561 - val_accuracy: 0.8392 - val_loss: 0.6538\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0393 - val_accuracy: 0.8470 - val_loss: 0.6034\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9870 - loss: 0.0398 - val_accuracy: 0.8477 - val_loss: 0.6583\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0329 - val_accuracy: 0.8426 - val_loss: 0.7326\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0458 - val_accuracy: 0.8485 - val_loss: 0.6816\n",
      "1-conv-128-nodes-1-dense-1766099726\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - accuracy: 0.6681 - loss: 0.6552 - val_accuracy: 0.7284 - val_loss: 0.5505\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7625 - loss: 0.5020 - val_accuracy: 0.7671 - val_loss: 0.4923\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8023 - loss: 0.4340 - val_accuracy: 0.7523 - val_loss: 0.5164\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8409 - loss: 0.3618 - val_accuracy: 0.7572 - val_loss: 0.5158\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8733 - loss: 0.3014 - val_accuracy: 0.7708 - val_loss: 0.5267\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9063 - loss: 0.2337 - val_accuracy: 0.7520 - val_loss: 0.6341\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9293 - loss: 0.1853 - val_accuracy: 0.7622 - val_loss: 0.6556\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9543 - loss: 0.1272 - val_accuracy: 0.7705 - val_loss: 0.7016\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9702 - loss: 0.0922 - val_accuracy: 0.7692 - val_loss: 0.7709\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9861 - loss: 0.0543 - val_accuracy: 0.7517 - val_loss: 1.0225\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9880 - loss: 0.0452 - val_accuracy: 0.7618 - val_loss: 0.9483\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9947 - loss: 0.0266 - val_accuracy: 0.7680 - val_loss: 1.0587\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9964 - loss: 0.0193 - val_accuracy: 0.7531 - val_loss: 1.2063\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0288 - val_accuracy: 0.7552 - val_loss: 1.1739\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.9894 - loss: 0.0354 - val_accuracy: 0.7496 - val_loss: 1.1517\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9967 - loss: 0.0151 - val_accuracy: 0.7622 - val_loss: 1.3360\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.7566 - val_loss: 1.3933\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7641 - val_loss: 1.4847\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.4405e-04 - val_accuracy: 0.7670 - val_loss: 1.5473\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 6.3607e-04 - val_accuracy: 0.7667 - val_loss: 1.6006\n",
      "2-conv-128-nodes-1-dense-1766099890\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:18:12.434899: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-19 00:18:13.530850: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_574', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6208 - val_accuracy: 0.7331 - val_loss: 0.5368\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.7532 - loss: 0.5067 - val_accuracy: 0.7886 - val_loss: 0.4537\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7996 - loss: 0.4376 - val_accuracy: 0.8037 - val_loss: 0.4268\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.8277 - loss: 0.3828 - val_accuracy: 0.8137 - val_loss: 0.4081\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.8533 - loss: 0.3391 - val_accuracy: 0.8110 - val_loss: 0.4091\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8710 - loss: 0.2979 - val_accuracy: 0.8115 - val_loss: 0.4161\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8979 - loss: 0.2494 - val_accuracy: 0.8205 - val_loss: 0.4471\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9217 - loss: 0.1946 - val_accuracy: 0.8203 - val_loss: 0.4751\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9398 - loss: 0.1506 - val_accuracy: 0.8109 - val_loss: 0.5560\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9611 - loss: 0.1088 - val_accuracy: 0.8110 - val_loss: 0.6137\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9758 - loss: 0.0697 - val_accuracy: 0.7755 - val_loss: 0.8373\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9814 - loss: 0.0544 - val_accuracy: 0.8002 - val_loss: 0.8464\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9856 - loss: 0.0426 - val_accuracy: 0.8055 - val_loss: 0.9129\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9920 - loss: 0.0274 - val_accuracy: 0.7996 - val_loss: 1.0081\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9927 - loss: 0.0238 - val_accuracy: 0.8022 - val_loss: 1.0655\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.8057 - val_loss: 1.1213\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9917 - loss: 0.0255 - val_accuracy: 0.8038 - val_loss: 1.1193\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.8009 - val_loss: 1.1740\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.8006 - val_loss: 1.3769\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.1643e-04 - val_accuracy: 0.8069 - val_loss: 1.4615\n",
      "3-conv-128-nodes-1-dense-1766100081\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-19 00:21:23.869980: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-19 00:21:24.925301: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_695', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 25ms/step - accuracy: 0.6691 - loss: 0.6063 - val_accuracy: 0.7328 - val_loss: 0.5321\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7524 - loss: 0.5018 - val_accuracy: 0.7808 - val_loss: 0.4586\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.8017 - loss: 0.4312 - val_accuracy: 0.7785 - val_loss: 0.4651\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8302 - loss: 0.3753 - val_accuracy: 0.7834 - val_loss: 0.4609\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.8517 - loss: 0.3307 - val_accuracy: 0.8456 - val_loss: 0.3498\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - accuracy: 0.8774 - loss: 0.2829 - val_accuracy: 0.8496 - val_loss: 0.3417\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9052 - loss: 0.2307 - val_accuracy: 0.8331 - val_loss: 0.3974\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.9268 - loss: 0.1859 - val_accuracy: 0.8496 - val_loss: 0.3676\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9453 - loss: 0.1418 - val_accuracy: 0.8499 - val_loss: 0.4060\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9585 - loss: 0.1078 - val_accuracy: 0.8450 - val_loss: 0.5015\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - accuracy: 0.9758 - loss: 0.0664 - val_accuracy: 0.8358 - val_loss: 0.6534\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9809 - loss: 0.0557 - val_accuracy: 0.8630 - val_loss: 0.4806\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9851 - loss: 0.0422 - val_accuracy: 0.8596 - val_loss: 0.5845\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0397 - val_accuracy: 0.8573 - val_loss: 0.6836\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9860 - loss: 0.0381 - val_accuracy: 0.8401 - val_loss: 0.7065\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9896 - loss: 0.0327 - val_accuracy: 0.8473 - val_loss: 0.7475\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9912 - loss: 0.0274 - val_accuracy: 0.8326 - val_loss: 0.7844\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0170 - val_accuracy: 0.8436 - val_loss: 0.8785\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9880 - loss: 0.0329 - val_accuracy: 0.8349 - val_loss: 1.0276\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9894 - loss: 0.0280 - val_accuracy: 0.8509 - val_loss: 0.8172\n",
      "1-conv-256-nodes-1-dense-1766100331\n",
      "Epoch 1/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.7052 - loss: 0.6334 - val_accuracy: 0.7449 - val_loss: 0.5115\n",
      "Epoch 2/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - accuracy: 0.8002 - loss: 0.4315 - val_accuracy: 0.7630 - val_loss: 0.4947\n",
      "Epoch 3/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.8629 - loss: 0.3193 - val_accuracy: 0.7628 - val_loss: 0.5375\n",
      "Epoch 4/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.9113 - loss: 0.2206 - val_accuracy: 0.7592 - val_loss: 0.6169\n",
      "Epoch 5/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9550 - loss: 0.1233 - val_accuracy: 0.7449 - val_loss: 0.9569\n",
      "Epoch 6/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9796 - loss: 0.0665 - val_accuracy: 0.7584 - val_loss: 0.8711\n",
      "Epoch 7/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9861 - loss: 0.0442 - val_accuracy: 0.7621 - val_loss: 0.9743\n",
      "Epoch 8/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9910 - loss: 0.0359 - val_accuracy: 0.7490 - val_loss: 1.2274\n",
      "Epoch 9/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9899 - loss: 0.0311 - val_accuracy: 0.7631 - val_loss: 1.1557\n",
      "Epoch 10/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9944 - loss: 0.0237 - val_accuracy: 0.7663 - val_loss: 1.2638\n",
      "Epoch 11/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.9939 - loss: 0.0212 - val_accuracy: 0.7537 - val_loss: 1.3683\n",
      "Epoch 12/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 33ms/step - accuracy: 0.9963 - loss: 0.0143 - val_accuracy: 0.7580 - val_loss: 1.3904\n",
      "Epoch 13/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.7461 - val_loss: 1.5326\n",
      "Epoch 14/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - accuracy: 0.9934 - loss: 0.0223 - val_accuracy: 0.7464 - val_loss: 1.4592\n",
      "Epoch 15/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 0.7561 - val_loss: 1.5192\n",
      "Epoch 16/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.7436 - val_loss: 1.5363\n",
      "Epoch 17/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 72ms/step - accuracy: 0.9956 - loss: 0.0135 - val_accuracy: 0.7438 - val_loss: 1.5121\n",
      "Epoch 18/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 64ms/step - accuracy: 0.9988 - loss: 0.0066 - val_accuracy: 0.7586 - val_loss: 1.6373\n",
      "Epoch 19/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 71ms/step - accuracy: 0.9941 - loss: 0.0191 - val_accuracy: 0.7511 - val_loss: 1.6590\n",
      "Epoch 20/20\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.7471 - val_loss: 1.6810\n",
      "2-conv-256-nodes-1-dense-1766100723\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_452/325500905.py\", line 52, in <module>\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 399, in fit\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 241, in function\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 125, in wrapper\n\nOut of memory while trying to allocate 852010368 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_1858043]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[1;32m     51\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/utils.py\", line 71, in preserve_context\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_452/325500905.py\", line 52, in <module>\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 399, in fit\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 241, in function\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 154, in multi_step_on_iterator\n\n  File \"/home/nigga/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 125, in wrapper\n\nOut of memory while trying to allocate 852010368 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_1858043]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"GPUs detected and configured: {gpus[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Falling back to CPU.\")\n",
    "\n",
    "X = pickle.load(open(\"/home/nigga/engine/X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"/home/nigga/engine/y.pickle\", \"rb\"))\n",
    "\n",
    "X = X / 255.0\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [64,128,256]\n",
    "conv_layers  = [1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME=\"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "            print(NAME)\n",
    "        \n",
    "            model = Sequential()            \n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            for l in range(conv_layer-1): \n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))            \n",
    "            # Compile\n",
    "            model.compile(\n",
    "                loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            model.fit(X, y, batch_size=32, epochs=20, validation_split=0.3,callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e88a8a-5ef2-4a1c-b418-5a4d9fc9ec1a",
   "metadata": {},
   "source": [
    "***\n",
    "Couche  \t      |  Rôle<br>\n",
    "***\n",
    "Conv2D            | (32 filtres)\tDétecte bords & formes simples<br>\n",
    "***\n",
    "\n",
    "MaxPool\t          | Réduit la taille<br>\n",
    "***\n",
    "Conv2D(64 filtres)|\tDétecte motifs plus complexes<br>\n",
    "***\n",
    "MaxPool           |\tRéduit encore<br>\n",
    "***\n",
    "Flatten\t          |Convertit en vecteur<br>\n",
    "***\n",
    "Dense             |(64)\tApprend les combinaisons de features<br>\n",
    "***\n",
    "Dense (1, sigmoid)|\tPrédit 0 ou 1<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f47ad0-1e60-43ca-9293-60c08f2a23d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
